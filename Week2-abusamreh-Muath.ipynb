{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a74b5e-5180-4544-86a0-b047a877eb8e",
   "metadata": {},
   "source": [
    "# Week 4 - Logistic Regression and Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5925a10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.16.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c24f12c-b364-40f0-b295-7c1ba88be680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, accuracy_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d156fa14",
   "metadata": {},
   "source": [
    "First Dataset: Acute Kidney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b27e0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"Acute Kidney.csv\" \n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "\n",
    "# Normalize columns (spaces/symbols -> underscores; lowercase)\n",
    "df.columns = (df.columns.astype(str)\n",
    "                .str.strip()\n",
    "                .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "                .str.replace(r\"[^0-9a-zA-Z_]\", \"\", regex=True)\n",
    "                .str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "628c5aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary target: mort_28_day\n"
     ]
    }
   ],
   "source": [
    "#Choose a BINARY target\n",
    "# Preference order; otherwise detect any 0/1 column; if none, derive from aki_stage>0\n",
    "preferred = [\"mort_28_day\", \"mort_90_day\", \"mort_1_year\"]\n",
    "bin_target = None\n",
    "for c in preferred:\n",
    "    if c in df.columns:\n",
    "        vals = pd.unique(df[c].dropna())\n",
    "        if set(vals).issubset({0, 1}):\n",
    "            bin_target = c\n",
    "            break\n",
    "\n",
    "derived_from = None\n",
    "if bin_target is None:\n",
    "    # auto-detect any 0/1 column\n",
    "    for c in df.columns:\n",
    "        if c in preferred:  # already checked\n",
    "            continue\n",
    "        if df[c].dropna().nunique() == 2 and set(pd.unique(df[c].dropna())).issubset({0, 1}):\n",
    "            bin_target = c\n",
    "            break\n",
    "\n",
    "if bin_target is None and \"akistage\" in df.columns:\n",
    "    # handle a possible column naming variant (just in case)\n",
    "    df.rename(columns={\"akistage\": \"aki_stage\"}, inplace=True)\n",
    "\n",
    "if bin_target is None and \"aki_stage\" in df.columns:\n",
    "    # Derive a binary AKI presence flag; exclude aki_stage from X to avoid leakage\n",
    "    df[\"aki_present\"] = (pd.to_numeric(df[\"aki_stage\"], errors=\"coerce\").fillna(0) > 0).astype(int)\n",
    "    bin_target = \"aki_present\"\n",
    "    derived_from = \"aki_stage\"\n",
    "\n",
    "if bin_target is None:\n",
    "    raise ValueError(\"Could not find a binary target. Please set bin_target manually (0/1 column).\")\n",
    "\n",
    "print(f\"Binary target: {bin_target}\" + (f\" (derived from {derived_from})\" if derived_from else \"\"))\n",
    "\n",
    "# Keep only rows with non-missing y\n",
    "y = df[bin_target].astype(int)\n",
    "mask = ~y.isna()\n",
    "df = df.loc[mask].reset_index(drop=True)\n",
    "y = y.loc[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54930f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: numeric vs categorical\n",
    "# Drop the target; if derived from aki_stage, drop aki_stage to avoid leakage\n",
    "X = df.drop(columns=[bin_target])\n",
    "if derived_from:\n",
    "    X = X.drop(columns=[derived_from], errors=\"ignore\")\n",
    "\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "\n",
    "# Quick NA handling – leave scaling/encoding to the pipeline, but fill obvious NaNs\n",
    "for c in num_cols:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(0.0)\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"category\").cat.add_categories([\"__missing__\"]).fillna(\"__missing__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6349041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor (Scaling + OHE)\n",
    "# Make OHE dense for LBFGS; handle both modern and older sklearns\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", ohe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77a6fe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.211 → class_weight=balanced\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance handling \n",
    "pos_rate = float(y.mean())\n",
    "use_balanced = (min(pos_rate, 1 - pos_rate) < 0.35)  # trigger if minority <35%\n",
    "print(f\"Positive rate: {pos_rate:.3f} → class_weight={'balanced' if use_balanced else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c2fe812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Build pipeline: Preprocess -> LogisticRegression\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=5000,\n",
    "    solver=\"lbfgs\",               # robust, handles L2 by default\n",
    "    class_weight=\"balanced\" if use_balanced else None\n",
    ")\n",
    "pipe = Pipeline(steps=[(\"pre\", pre), (\"clf\", log_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a8883de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 4 — Logistic Regression with Scaling (Stratified 5-fold CV) ===\n",
      "   Metric 5-fold CV (mean ± std)\n",
      " Accuracy        0.9900 ± 0.0026\n",
      "  ROC-AUC        0.9998 ± 0.0002\n",
      "Precision        0.9549 ± 0.0112\n",
      "   Recall        1.0000 ± 0.0000\n",
      "       F1        0.9769 ± 0.0059\n"
     ]
    }
   ],
   "source": [
    "#  Stratified 5-fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_validate(\n",
    "    pipe, X, y, cv=cv,\n",
    "    scoring={\n",
    "        \"accuracy\": \"accuracy\",\n",
    "        \"roc_auc\": \"roc_auc\",\n",
    "        \"precision\": \"precision\",\n",
    "        \"recall\": \"recall\",\n",
    "        \"f1\": \"f1\",\n",
    "    },\n",
    "    n_jobs=-1, return_estimator=False\n",
    ")\n",
    "\n",
    "def pm(m):\n",
    "    return f\"{np.mean(m):.4f} ± {np.std(m):.4f}\"\n",
    "\n",
    "cv_table = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"ROC-AUC\", \"Precision\", \"Recall\", \"F1\"],\n",
    "    \"5-fold CV (mean ± std)\": [\n",
    "        pm(scores[\"test_accuracy\"]),\n",
    "        pm(scores[\"test_roc_auc\"]),\n",
    "        pm(scores[\"test_precision\"]),\n",
    "        pm(scores[\"test_recall\"]),\n",
    "        pm(scores[\"test_f1\"]),\n",
    "    ],\n",
    "})\n",
    "print(\"\\n=== Week 4 — Logistic Regression with Scaling (Stratified 5-fold CV) ===\")\n",
    "print(cv_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b71f7cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 4 — 30% Holdout (threshold=0.5) ===\n",
      " Accuracy  ROC-AUC  Precision  Recall       F1\n",
      " 0.988343 0.999666   0.947566     1.0 0.973077\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "     0    1\n",
      "0  934   14\n",
      "1    0  253\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9852    0.9926       948\n",
      "           1     0.9476    1.0000    0.9731       253\n",
      "\n",
      "    accuracy                         0.9883      1201\n",
      "   macro avg     0.9738    0.9926    0.9828      1201\n",
      "weighted avg     0.9890    0.9883    0.9885      1201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Holdout 30% (consistent benchmark)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "pipe.fit(X_tr, y_tr)\n",
    "probs = pipe.predict_proba(X_te)[:, 1]\n",
    "pred  = (probs >= 0.5).astype(int)\n",
    "\n",
    "hold = {\n",
    "    \"Accuracy\":  accuracy_score(y_te, pred),\n",
    "    \"ROC-AUC\":   roc_auc_score(y_te, probs),\n",
    "    \"Precision\": precision_score(y_te, pred, zero_division=0),\n",
    "    \"Recall\":    recall_score(y_te, pred, zero_division=0),\n",
    "    \"F1\":        f1_score(y_te, pred, zero_division=0),\n",
    "}\n",
    "hold_table = pd.DataFrame([hold])\n",
    "print(\"\\n=== Week 4 — 30% Holdout (threshold=0.5) ===\")\n",
    "print(hold_table.to_string(index=False))\n",
    "\n",
    "print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_te, pred), index=[\"0\",\"1\"], columns=[\"0\",\"1\"]))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_te, pred, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e9c3217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top coefficients by |magnitude| (standardized/OHE space):\n",
      "    feature      coef  abs_coef\n",
      "    cox_los -8.825911  8.825911\n",
      " unit_TSICU  0.707147  0.707147\n",
      "         ck -0.640751  0.640751\n",
      "  unit_CSRU -0.541600  0.541600\n",
      "          p -0.399205  0.399205\n",
      "         ne  0.386041  0.386041\n",
      "        wbc  0.385192  0.385192\n",
      "         ph  0.349329  0.349329\n",
      "        age -0.330786  0.330786\n",
      "        plr  0.320051  0.320051\n",
      "     sapsii  0.289764  0.289764\n",
      "  pulmonary  0.267673  0.267673\n",
      "        nlr -0.257624  0.257624\n",
      " race_other  0.239297  0.239297\n",
      "        hiv  0.225951  0.225951\n",
      "     sepsis -0.225097  0.225097\n",
      " malignancy -0.218252  0.218252\n",
      "         ly  0.216421  0.216421\n",
      "         bp  0.215785  0.215785\n",
      "mort_90_day -0.204247  0.204247\n"
     ]
    }
   ],
   "source": [
    "# Top coefficients (interpretability) \n",
    "# Refit on all data to list the largest-magnitude coefficients\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# Recover feature names from preprocessor\n",
    "num_names = list(num_cols)\n",
    "try:\n",
    "    cat_names = list(pipe.named_steps[\"pre\"].named_transformers_[\"cat\"].get_feature_names_out(cat_cols)) if len(cat_cols) else []\n",
    "except Exception:\n",
    "    cat_names = []\n",
    "feat_names = np.array(num_names + cat_names, dtype=object)\n",
    "\n",
    "coefs = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "order = np.argsort(np.abs(coefs))[::-1]\n",
    "k = min(20, len(order))\n",
    "top = pd.DataFrame({\n",
    "    \"feature\": feat_names[order][:k],\n",
    "    \"coef\": coefs[order][:k],\n",
    "    \"abs_coef\": np.abs(coefs[order][:k])\n",
    "})\n",
    "print(\"\\nTop coefficients by |magnitude| (standardized/OHE space):\")\n",
    "print(top.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3161eb9",
   "metadata": {},
   "source": [
    "Week 4 — Logistic Regression + Feature Scaling (Acute Kidney)\n",
    "Objective\n",
    "\n",
    "Build and evaluate a logistic regression model (with proper feature scaling) to predict a binary outcome from the Acute Kidney dataset. Report stratified 5-fold CV and a 30% holdout using Accuracy, ROC-AUC, Precision, Recall, and F1. Interpret the most influential features.\n",
    "\n",
    "\n",
    "Preprocessing\n",
    "\n",
    "Column cleanup: lowercased, spaces/symbols → underscores.\n",
    "\n",
    "Numeric: imputed with 0.0, then StandardScaler.\n",
    "\n",
    "Categorical: One-Hot Encoded (handle_unknown=\"ignore\").\n",
    "\n",
    "Pipeline: ColumnTransformer([scale numerics, OHE categoricals]) → LogisticRegression(lbfgs, max_iter=5000, class_weight=\"balanced\" if needed)\n",
    "\n",
    "Train/Test split: 70/30 with stratification.\n",
    "\n",
    "Interpretation\n",
    "\n",
    "Operating point: At 0.50 threshold, Recall = <…> and Precision = <…>; choose a threshold that matches clinical cost (e.g., prioritize Recall to avoid missed positives).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef5673c",
   "metadata": {},
   "source": [
    "Second Dataset: Colorectal cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "231e21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & tidy\n",
    "DATA_PATH = \"colorectal_cancer_dataset.csv\" \n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "df.columns = (df.columns.astype(str)\n",
    "                .str.strip()\n",
    "                .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "                .str.replace(r\"[^0-9a-zA-Z_]\", \"\", regex=True)\n",
    "                .str.lower())\n",
    "\n",
    "FORCE_TARGET = None                               # e.g., \"survival_status\" to force a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f5b6b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary target created: binary_target_auto  ← mortality ; details: {'type': 'direct_status'}\n"
     ]
    }
   ],
   "source": [
    "# Choose/derive a BINARY target \n",
    "def try_numeric_01(s: pd.Series):\n",
    "    vals = s.dropna().unique()\n",
    "    if len(vals) == 0: return None\n",
    "    # try to coerce to numeric\n",
    "    c = pd.to_numeric(s, errors=\"coerce\")\n",
    "    ok = c.dropna().isin([0,1]).all() and c.dropna().nunique() == 2\n",
    "    return c.astype(\"Int64\") if ok else None\n",
    "\n",
    "def try_boolish_map(s: pd.Series):\n",
    "    m = s.astype(str).str.strip().str.lower()\n",
    "    mapping = {\n",
    "        \"yes\":1,\"y\":1,\"true\":1,\"t\":1,\"1\":1,\"pos\":1,\"positive\":1,\"present\":1,\"dead\":1,\"deceased\":1,\"event\":1,\n",
    "        \"no\":0,\"n\":0,\"false\":0,\"f\":0,\"0\":0,\"neg\":0,\"negative\":0,\"absent\":0,\"alive\":0,\"nonevent\":0\n",
    "    }\n",
    "    mapped = m.map(mapping)\n",
    "    if mapped.dropna().nunique() == 2 and set(mapped.dropna().unique()) <= {0,1}:\n",
    "        return mapped.astype(int)\n",
    "    return None\n",
    "\n",
    "def derive_from_stage(frame: pd.DataFrame):\n",
    "    stage_like = [c for c in frame.columns if re.search(r\"stage\", c)]\n",
    "    if not stage_like: return None, None\n",
    "    col = stage_like[0]\n",
    "    s = frame[col].astype(str).str.upper()\n",
    "    adv = s.str.contains(\"III\") | s.str.contains(\"IV\") | s.str.contains(r\"\\b3\\b\") | s.str.contains(r\"\\b4\\b\")\n",
    "    if adv.notna().any():\n",
    "        return adv.astype(int), col\n",
    "    return None, None\n",
    "\n",
    "def derive_from_numeric_threshold(frame: pd.DataFrame, candidates=(\"survival_months\",\"overall_survival\",\"os_months\",\"dfs_months\",\"pfs_months\",\"los\",\"length_of_stay\",\"tumor_size\",\"tumor_volume\",\"age\",\"bmi\")):\n",
    "    for c in candidates:\n",
    "        if c in frame.columns:\n",
    "            num = pd.to_numeric(frame[c], errors=\"coerce\")\n",
    "            if num.dropna().nunique() >= 10:\n",
    "                thr = float(np.nanmedian(num))\n",
    "                return (num < thr).astype(int), c, thr\n",
    "    # last resort: pick the numeric with largest variance\n",
    "    nums = frame.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "    if not nums: return None, None, None\n",
    "    var = frame[nums].var(numeric_only=True).sort_values(ascending=False)\n",
    "    for c in var.index:\n",
    "        num = pd.to_numeric(frame[c], errors=\"coerce\")\n",
    "        if num.dropna().nunique() >= 10:\n",
    "            thr = float(np.nanmedian(num))\n",
    "            return (num < thr).astype(int), c, thr\n",
    "    return None, None, None\n",
    "\n",
    "def choose_binary_target(frame: pd.DataFrame, force=None):\n",
    "    if force is not None:\n",
    "        y = try_numeric_01(frame[force]) or try_boolish_map(frame[force])\n",
    "        if y is None: raise ValueError(f\"FORCE_TARGET='{force}' is not binary/boolean-mappable.\")\n",
    "        return y, (\"forced:\"+force), [force], {\"type\":\"forced\"}\n",
    "    # priority 1: known status/event/mortality names, numeric 0/1 or yes/no\n",
    "    prio = [\"survival_status\",\"death_event\",\"dead\",\"event\",\"mort_30_day\",\"mort_90_day\",\"mortality\",\"recurrence\",\"metastasis\",\"progression\",\"relapse\",\"outcome\",\"response\"]\n",
    "    for c in prio:\n",
    "        if c in frame.columns:\n",
    "            y = try_numeric_01(frame[c]) or try_boolish_map(frame[c])\n",
    "            if y is not None: \n",
    "                return y, c, [c], {\"type\":\"direct_status\"}\n",
    "    # priority 2: any other column that cleanly maps to 0/1 and has a status-like name\n",
    "    keypat = re.compile(r\"(status|event|recurr|metast|mort|death|progress|outcome|response)\")\n",
    "    for c in frame.columns:\n",
    "        if keypat.search(c):\n",
    "            y = try_numeric_01(frame[c]) or try_boolish_map(frame[c])\n",
    "            if y is not None:\n",
    "                return y, c, [c], {\"type\":\"keyword_status\"}\n",
    "    # priority 3: stage-based\n",
    "    y_stage, stage_col = derive_from_stage(frame)\n",
    "    if y_stage is not None:\n",
    "        return y_stage, f\"advanced_from:{stage_col}\", [stage_col], {\"type\":\"stage_derived\"}\n",
    "    # priority 4: numeric threshold (survival first; else variance-max numeric)\n",
    "    y_thr, src, thr = derive_from_numeric_threshold(frame)\n",
    "    if y_thr is not None:\n",
    "        note = {\"type\":\"threshold_derived\", \"source\":src, \"threshold\":thr}\n",
    "        return y_thr, f\"thr_from:{src}\", [src], note\n",
    "    return None, None, None, None\n",
    "\n",
    "y_series, target_info, leakage_cols, info = choose_binary_target(df, force=FORCE_TARGET)\n",
    "if y_series is None:\n",
    "    raise ValueError(\"No binary target found/derivable. Set FORCE_TARGET='your_binary_column' to specify one.\")\n",
    "\n",
    "bin_target = \"binary_target_auto\"\n",
    "df[bin_target] = y_series.astype(int)\n",
    "print(f\"Binary target created: {bin_target}  ← {target_info} ; details: {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1584c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build X/y and basic cleaning\n",
    "y = df[bin_target].astype(int)\n",
    "X = df.drop(columns=[bin_target] + (leakage_cols or []), errors=\"ignore\")   # drop source columns to avoid leakage\n",
    "\n",
    "num_cols = X.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "for c in num_cols:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(0.0)\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"category\").cat.add_categories([\"__missing__\"]).fillna(\"__missing__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "915300aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.401 → class_weight=None\n"
     ]
    }
   ],
   "source": [
    "# Preprocess (scale + OHE) and model\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", ohe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "pos_rate = float(y.mean())\n",
    "use_balanced = (min(pos_rate, 1-pos_rate) < 0.35)\n",
    "print(f\"Positive rate: {pos_rate:.3f} → class_weight={'balanced' if use_balanced else 'None'}\")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", LogisticRegression(max_iter=5000, solver=\"lbfgs\", class_weight=(\"balanced\" if use_balanced else None)))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4349ca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 4 — Logistic Regression with Scaling (Stratified 5-fold CV) ===\n",
      "   Metric 5-fold CV (mean ± std)\n",
      " Accuracy        0.5991 ± 0.0000\n",
      "  ROC-AUC        0.4972 ± 0.0021\n",
      "Precision        0.0000 ± 0.0000\n",
      "   Recall        0.0000 ± 0.0000\n",
      "       F1        0.0000 ± 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Stratified 5-fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_validate(\n",
    "    pipe, X, y, cv=cv,\n",
    "    scoring={\"accuracy\":\"accuracy\",\"roc_auc\":\"roc_auc\",\"precision\":\"precision\",\"recall\":\"recall\",\"f1\":\"f1\"},\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pm = lambda m: f\"{np.mean(m):.4f} ± {np.std(m):.4f}\"\n",
    "cv_table = pd.DataFrame({\n",
    "    \"Metric\":[\"Accuracy\",\"ROC-AUC\",\"Precision\",\"Recall\",\"F1\"],\n",
    "    \"5-fold CV (mean ± std)\":[pm(scores[\"test_accuracy\"]), pm(scores[\"test_roc_auc\"]), pm(scores[\"test_precision\"]), pm(scores[\"test_recall\"]), pm(scores[\"test_f1\"])]\n",
    "})\n",
    "print(\"\\n=== Week 4 — Logistic Regression with Scaling (Stratified 5-fold CV) ===\")\n",
    "print(cv_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb415ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 4 — 30% Holdout (threshold=0.5) ===\n",
      " Accuracy  ROC-AUC  Precision  Recall  F1\n",
      " 0.599144 0.498672        0.0     0.0 0.0\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "       0  1\n",
      "0  30107  0\n",
      "1  20143  0\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5991    1.0000    0.7493     30107\n",
      "           1     0.0000    0.0000    0.0000     20143\n",
      "\n",
      "    accuracy                         0.5991     50250\n",
      "   macro avg     0.2996    0.5000    0.3747     50250\n",
      "weighted avg     0.3590    0.5991    0.4490     50250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#30% Holdout\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "pipe.fit(X_tr, y_tr)\n",
    "probs = pipe.predict_proba(X_te)[:,1]\n",
    "pred  = (probs >= 0.5).astype(int)\n",
    "\n",
    "hold = {\n",
    "    \"Accuracy\": accuracy_score(y_te, pred),\n",
    "    \"ROC-AUC\":  roc_auc_score(y_te, probs),\n",
    "    \"Precision\":precision_score(y_te, pred, zero_division=0),\n",
    "    \"Recall\":   recall_score(y_te, pred, zero_division=0),\n",
    "    \"F1\":       f1_score(y_te, pred, zero_division=0),\n",
    "}\n",
    "hold_table = pd.DataFrame([hold])\n",
    "print(\"\\n=== Week 4 — 30% Holdout (threshold=0.5) ===\")\n",
    "print(hold_table.to_string(index=False))\n",
    "\n",
    "print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_te, pred), index=[\"0\",\"1\"], columns=[\"0\",\"1\"]))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_te, pred, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d63fffd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top coefficients by |magnitude| (standardized/OHE space):\n",
      "                           feature      coef  abs_coef\n",
      "              country_South Africa -0.049450  0.049450\n",
      "                    country_Brazil -0.030103  0.030103\n",
      "                   country_Germany -0.029114  0.029114\n",
      "               survival_5_years_No -0.028587  0.028587\n",
      "    inflammatory_bowel_disease_Yes -0.028266  0.028266\n",
      "              genetic_mutation_Yes -0.027000  0.027000\n",
      "                          gender_F -0.026656  0.026656\n",
      "             physical_activity_Low -0.026249  0.026249\n",
      "                     country_Italy  0.024709  0.024709\n",
      "               smoking_history_Yes -0.024687  0.024687\n",
      "           alcohol_consumption_Yes -0.024298  0.024298\n",
      "                early_detection_No -0.023764  0.023764\n",
      "              urban_or_rural_Rural -0.023419  0.023419\n",
      "            survival_prediction_No -0.022146  0.022146\n",
      "          insurance_status_Insured -0.022136  0.022136\n",
      "                      diabetes_Yes -0.021746  0.021746\n",
      "                obesity_bmi_Normal -0.021594  0.021594\n",
      "                family_history_Yes -0.021393  0.021393\n",
      "           screening_history_Never -0.021378  0.021378\n",
      "economic_classification_Developing -0.021354  0.021354\n"
     ]
    }
   ],
   "source": [
    "# Top coefficients (interpretability)\n",
    "pipe.fit(X, y)\n",
    "num_names = list(num_cols)\n",
    "try:\n",
    "    cat_names = list(pipe.named_steps[\"pre\"].named_transformers_[\"cat\"].get_feature_names_out(cat_cols)) if len(cat_cols) else []\n",
    "except Exception:\n",
    "    cat_names = []\n",
    "feat_names = np.array(num_names + cat_names, dtype=object)\n",
    "\n",
    "coefs = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "order = np.argsort(np.abs(coefs))[::-1]\n",
    "k = min(20, len(order))\n",
    "top = pd.DataFrame({\"feature\": feat_names[order][:k], \"coef\": coefs[order][:k], \"abs_coef\": np.abs(coefs[order][:k])})\n",
    "print(\"\\nTop coefficients by |magnitude| (standardized/OHE space):\")\n",
    "print(top.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68d7fd",
   "metadata": {},
   "source": [
    "Week 4 — Logistic Regression + Feature Scaling (Colorectal)\n",
    "Objective\n",
    "\n",
    "Build and evaluate a logistic regression classifier (with proper feature scaling and one-hot encoding) on the colorectal_cancer_dataset.csv. Report stratified 5-fold CV and a 30% holdout using Accuracy, ROC-AUC, Precision, Recall, and F1. Interpret the most influential features.\n",
    "\n",
    "Target (how it was chosen)\n",
    "\n",
    "Use any clear 0/1 status column (e.g., survival_status, death_event, mort_90_day, recurrence, …), including yes/no / true/false mapping.\n",
    "\n",
    "If none, derive advanced stage from a stage column (III/IV → 1; I/II → 0).\n",
    "\n",
    "If none, derive short_survival from survival_months via median split.\n",
    "\n",
    "If still none, median-split the highest-variance numeric column.\n",
    "→ The chosen target is stored as binary_target_auto and the console prints:\n",
    "Binary target created: binary_target_auto ← <rule/details>\n",
    "\n",
    "If you must lock a specific label, set FORCE_TARGET = \"your_column\" near the top.\n",
    "\n",
    "Features & Preprocessing\n",
    "\n",
    "Numeric features: impute 0.0 → StandardScaler.\n",
    "\n",
    "Categorical features: fill \"__missing__\" → One-Hot Encoder (handle_unknown=\"ignore\").\n",
    "\n",
    "Leakage prevention: if the label was derived from stage or survival_months (or any source column), that source is dropped from X.\n",
    "\n",
    "Pipeline:\n",
    "ColumnTransformer([scale numerics, OHE categoricals]) → LogisticRegression(lbfgs, max_iter=5000, class_weight=\"balanced\" if minority < 35%)\n",
    "\n",
    "Validation Protocol\n",
    "\n",
    "Stratified 5-fold CV (keeps class distribution per fold) with metrics:\n",
    "\n",
    "Accuracy, ROC-AUC, Precision, Recall, F1 (macro-style positive class focus).\n",
    "\n",
    "Shared 30% holdout for an apples-to-apples test after CV.\n",
    "\n",
    "Threshold fixed at 0.50 for holdout classification; ROC-AUC uses probabilities.\n",
    "\n",
    "Interpretability (Top Coefficients)\n",
    "\n",
    "The script prints Top 20 features by |coefficient| (in the standardized/OHE space).\n",
    "\n",
    "Positive coef → increases log-odds of the positive class; negative → decreases.\n",
    "\n",
    "Since numerics are scaled, magnitudes across numeric features are comparable; OHE dummies are 0/1.\n",
    "\n",
    "Paste a few highlights here:\n",
    "• feature_A (+): higher odds of positive outcome.\n",
    "• feature_B (−): lower odds of positive outcome.\n",
    "• stage_* dummies (if present) and key labs/vitals often rank highly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96124c67",
   "metadata": {},
   "source": [
    "Third Dataset: Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f2a3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_PATHS = [\n",
    "    \"/mnt/data/diabetes_012_health_indicators_BRFSS2015.csv\",\n",
    "    \"diabetes_012_health_indicators_BRFSS2015.csv\",\n",
    "]\n",
    "# If True → label = 1 only for Diabetes (2); if False → label = 1 for Prediabetes(1) or Diabetes(2)\n",
    "DIABETES_ONLY = False     # change to True if you want 2 vs (0/1)\n",
    "FORCE_TARGET = None       # e.g., \"diabetes_binary\" if you already have a 0/1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a6c53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & tidy\n",
    "for p in POSSIBLE_PATHS:\n",
    "    if os.path.exists(p):\n",
    "        DATA_PATH = p\n",
    "        break\n",
    "else:\n",
    "    DATA_PATH = POSSIBLE_PATHS[0]  # will raise if missing\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, low_memory=True)\n",
    "\n",
    "# normalize column names\n",
    "df.columns = (df.columns.astype(str)\n",
    "              .str.strip()\n",
    "              .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "              .str.replace(r\"[^0-9a-zA-Z_]\", \"\", regex=True)\n",
    "              .str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0e5004d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary target: prediabetes_or_diabetes (1/2 vs 0) from diabetes_012\n",
      "Positive rate: 0.158\n"
     ]
    }
   ],
   "source": [
    "#  Binary target selection/derivation\n",
    "def coerce_binary_series(s: pd.Series):\n",
    "    \"\"\"Accepts 0/1 ints or maps common boolean-ish strings to 0/1. Return None if not clean binary.\"\"\"\n",
    "    # numeric 0/1?\n",
    "    try_num = pd.to_numeric(s, errors=\"coerce\")\n",
    "    if try_num.dropna().isin([0,1]).all() and try_num.dropna().nunique() == 2:\n",
    "        return try_num.astype(int)\n",
    "\n",
    "    # string yes/no/true/false mapping\n",
    "    m = s.astype(str).str.strip().str.lower()\n",
    "    mapping = {\"yes\":1,\"y\":1,\"true\":1,\"t\":1,\"1\":1,\"pos\":1,\"positive\":1,\n",
    "               \"no\":0,\"n\":0,\"false\":0,\"f\":0,\"0\":0,\"neg\":0,\"negative\":0}\n",
    "    mapped = m.map(mapping)\n",
    "    if mapped.dropna().nunique() == 2 and set(mapped.dropna().unique()) <= {0,1}:\n",
    "        return mapped.astype(int)\n",
    "\n",
    "    return None\n",
    "\n",
    "bin_target = None\n",
    "source_cols_to_drop = []\n",
    "\n",
    "if FORCE_TARGET is not None and FORCE_TARGET in df.columns:\n",
    "    y_tmp = coerce_binary_series(df[FORCE_TARGET])\n",
    "    if y_tmp is None:\n",
    "        raise ValueError(f\"FORCE_TARGET='{FORCE_TARGET}' is not binary/boolean-mappable.\")\n",
    "    y = y_tmp.astype(int)\n",
    "    bin_target = f\"{FORCE_TARGET} (forced)\"\n",
    "else:\n",
    "    # 1) If 'diabetes_binary' exists and is clean 0/1, use it\n",
    "    if \"diabetes_binary\" in df.columns:\n",
    "        y_tmp = coerce_binary_series(df[\"diabetes_binary\"])\n",
    "        if y_tmp is not None:\n",
    "            y = y_tmp.astype(int)\n",
    "            bin_target = \"diabetes_binary\"\n",
    "\n",
    "    # 2) Else derive from 'diabetes_012' if present\n",
    "    if bin_target is None and \"diabetes_012\" in df.columns:\n",
    "        d012 = pd.to_numeric(df[\"diabetes_012\"], errors=\"coerce\")\n",
    "        if DIABETES_ONLY:\n",
    "            # 2 vs (0/1)\n",
    "            y = (d012 == 2).astype(int)\n",
    "            bin_target = \"diabetes_only (2 vs 0/1) from diabetes_012\"\n",
    "        else:\n",
    "            # 1/2 vs 0\n",
    "            y = (d012 >= 1).astype(int)\n",
    "            bin_target = \"prediabetes_or_diabetes (1/2 vs 0) from diabetes_012\"\n",
    "        source_cols_to_drop.append(\"diabetes_012\")\n",
    "\n",
    "# If still none, try to find any clean 0/1 column named like diabetes\n",
    "if bin_target is None:\n",
    "    for c in df.columns:\n",
    "        if \"diab\" in c:\n",
    "            y_tmp = coerce_binary_series(df[c])\n",
    "            if y_tmp is not None:\n",
    "                y = y_tmp.astype(int)\n",
    "                bin_target = f\"{c} (auto)\"\n",
    "                break\n",
    "\n",
    "if bin_target is None:\n",
    "    raise ValueError(\"No suitable binary target found or derivable. \"\n",
    "                     \"Set FORCE_TARGET to a 0/1 column or ensure diabetes_012/diabetes_binary is present.\")\n",
    "\n",
    "print(f\"Binary target: {bin_target}\")\n",
    "pos_rate = float(y.mean())\n",
    "print(f\"Positive rate: {pos_rate:.3f}\")\n",
    "\n",
    "# Keep only rows with non-missing y\n",
    "mask = ~y.isna()\n",
    "y = y.loc[mask].reset_index(drop=True)\n",
    "df = df.loc[mask].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11ed717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: numeric vs categorical\n",
    "X = df.drop(columns=source_cols_to_drop, errors=\"ignore\")  # drop diabetes_012 if used\n",
    "# Also drop the target column itself if it exists in X\n",
    "for c in [\"diabetes_binary\"]:\n",
    "    X = X.drop(columns=[c], errors=\"ignore\")\n",
    "\n",
    "num_cols = X.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "\n",
    "# Quick NA handling (leave scaling/encoding to the pipeline)\n",
    "for c in num_cols:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"category\").cat.add_categories([\"__missing__\"]).fillna(\"__missing__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13c8e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Preprocessor (Scaling + OHE)\n",
    "# Handle both modern and older sklearns for OHE arg name\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", ohe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3af35627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight: balanced\n"
     ]
    }
   ],
   "source": [
    "#  Model (handle imbalance if needed)\n",
    "use_balanced = (min(pos_rate, 1 - pos_rate) < 0.35)\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=5000,\n",
    "    solver=\"lbfgs\",\n",
    "    class_weight=\"balanced\" if use_balanced else None\n",
    ")\n",
    "pipe = Pipeline(steps=[(\"pre\", pre), (\"clf\", log_reg)])\n",
    "print(f\"class_weight: {'balanced' if use_balanced else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ecf53ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 4 — Logistic Regression with Scaling (Stratified 5-fold CV) ===\n",
      "   Metric 5-fold CV (mean ± std)\n",
      " Accuracy        0.7292 ± 0.0017\n",
      "  ROC-AUC        0.8177 ± 0.0015\n",
      "Precision        0.3397 ± 0.0019\n",
      "   Recall        0.7609 ± 0.0026\n",
      "       F1        0.4697 ± 0.0023\n"
     ]
    }
   ],
   "source": [
    "# Stratified 5-fold CV \n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_validate(\n",
    "    pipe, X, y, cv=cv,\n",
    "    scoring={\n",
    "        \"accuracy\": \"accuracy\",\n",
    "        \"roc_auc\": \"roc_auc\",\n",
    "        \"precision\": \"precision\",\n",
    "        \"recall\": \"recall\",\n",
    "        \"f1\": \"f1\",\n",
    "    },\n",
    "    n_jobs=-1, return_estimator=False\n",
    ")\n",
    "\n",
    "def pm(m): return f\"{np.mean(m):.4f} ± {np.std(m):.4f}\"\n",
    "\n",
    "cv_table = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"ROC-AUC\", \"Precision\", \"Recall\", \"F1\"],\n",
    "    \"5-fold CV (mean ± std)\": [\n",
    "        pm(scores[\"test_accuracy\"]),\n",
    "        pm(scores[\"test_roc_auc\"]),\n",
    "        pm(scores[\"test_precision\"]),\n",
    "        pm(scores[\"test_recall\"]),\n",
    "        pm(scores[\"test_f1\"]),\n",
    "    ],\n",
    "})\n",
    "print(\"\\n=== Week 4 — Logistic Regression with Scaling (Stratified 5-fold CV) ===\")\n",
    "print(cv_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8841b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 4 — 30% Holdout (threshold=0.5) ===\n",
      " Accuracy  ROC-AUC  Precision   Recall       F1\n",
      " 0.729699 0.817294    0.34038 0.762612 0.470679\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "       0      1\n",
      "0  46387  17724\n",
      "1   2847   9146\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9422    0.7235    0.8185     64111\n",
      "           1     0.3404    0.7626    0.4707     11993\n",
      "\n",
      "    accuracy                         0.7297     76104\n",
      "   macro avg     0.6413    0.7431    0.6446     76104\n",
      "weighted avg     0.8473    0.7297    0.7637     76104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 30% Holdout\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "pipe.fit(X_tr, y_tr)\n",
    "probs = pipe.predict_proba(X_te)[:, 1]\n",
    "pred  = (probs >= 0.5).astype(int)\n",
    "\n",
    "hold = {\n",
    "    \"Accuracy\":  accuracy_score(y_te, pred),\n",
    "    \"ROC-AUC\":   roc_auc_score(y_te, probs),\n",
    "    \"Precision\": precision_score(y_te, pred, zero_division=0),\n",
    "    \"Recall\":    recall_score(y_te, pred, zero_division=0),\n",
    "    \"F1\":        f1_score(y_te, pred, zero_division=0),\n",
    "}\n",
    "hold_table = pd.DataFrame([hold])\n",
    "print(\"\\n=== Week 4 — 30% Holdout (threshold=0.5) ===\")\n",
    "print(hold_table.to_string(index=False))\n",
    "\n",
    "print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_te, pred), index=[\"0\",\"1\"], columns=[\"0\",\"1\"]))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_te, pred, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ac8a9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top coefficients by |magnitude| (standardized/OHE space):\n",
      "             feature      coef  abs_coef\n",
      "             genhlth  0.587020  0.587020\n",
      "                 bmi  0.484859  0.484859\n",
      "                 age  0.457165  0.457165\n",
      "              highbp  0.340495  0.340495\n",
      "            highchol  0.294048  0.294048\n",
      "           cholcheck  0.231553  0.231553\n",
      "   hvyalcoholconsump -0.148657  0.148657\n",
      "              income -0.129141  0.129141\n",
      "                 sex  0.127098  0.127098\n",
      "heartdiseaseorattack  0.065079  0.065079\n",
      "            physhlth -0.057793  0.057793\n",
      "           education -0.044296  0.044296\n",
      "            diffwalk  0.030459  0.030459\n",
      "         nodocbccost  0.029762  0.029762\n",
      "              stroke  0.027140  0.027140\n",
      "              fruits -0.023599  0.023599\n",
      "        physactivity -0.018660  0.018660\n",
      "            menthlth -0.018013  0.018013\n",
      "             veggies -0.016170  0.016170\n",
      "       anyhealthcare  0.010144  0.010144\n"
     ]
    }
   ],
   "source": [
    "# Top coefficients (interpretability)\n",
    "# Refit on all data to list the largest-magnitude coefficients\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# Recover feature names from the preprocessor\n",
    "num_names = list(num_cols)\n",
    "try:\n",
    "    cat_names = list(pipe.named_steps[\"pre\"].named_transformers_[\"cat\"].get_feature_names_out(cat_cols)) if len(cat_cols) else []\n",
    "except Exception:\n",
    "    cat_names = []\n",
    "feat_names = np.array(num_names + cat_names, dtype=object)\n",
    "\n",
    "coefs = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "order = np.argsort(np.abs(coefs))[::-1]\n",
    "k = min(20, len(order))\n",
    "top = pd.DataFrame({\n",
    "    \"feature\": feat_names[order][:k],\n",
    "    \"coef\": coefs[order][:k],\n",
    "    \"abs_coef\": np.abs(coefs[order][:k])\n",
    "})\n",
    "print(\"\\nTop coefficients by |magnitude| (standardized/OHE space):\")\n",
    "print(top.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b4f881",
   "metadata": {},
   "source": [
    "Week 4 — Logistic Regression + Feature Scaling (Diabetes BRFSS2015)\n",
    "Objective\n",
    "\n",
    "Train and evaluate a logistic regression classifier (with proper feature scaling and one-hot encoding) to predict diabetes status from the BRFSS 2015 health indicators dataset. Report stratified 5-fold CV and a 30% holdout using Accuracy, ROC-AUC, Precision, Recall, and F1. Interpret the most influential features.\n",
    "\n",
    "\n",
    "If diabetes_binary exists, used directly; else derived from diabetes_012 as:\n",
    "\n",
    "Default: Prediabetes or Diabetes (1/2) vs No (0)\n",
    "\n",
    "Optional: Diabetes only (2) vs (0/1) if DIABETES_ONLY=True\n",
    "\n",
    "\n",
    "Preprocessing\n",
    "\n",
    "Column cleanup: lowercased, spaces/symbols → underscores.\n",
    "\n",
    "Numeric: imputed with 0.0, then StandardScaler.\n",
    "\n",
    "Categorical: __missing__ placeholder then One-Hot Encoder (handle_unknown=\"ignore\").\n",
    "\n",
    "Pipeline: ColumnTransformer([scale numerics, OHE categoricals]) → LogisticRegression(lbfgs, max_iter=5000, class_weight=\"balanced\" if minority < 35%)\n",
    "\n",
    "Split: 70/30 stratified train/holdout.\n",
    "\n",
    "\n",
    "Operating point: At threshold 0.50. If public-health screening is the goal, consider increasing Recall (lower threshold) at the cost of Precision.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
